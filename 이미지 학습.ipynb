{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 임폴트\n",
    "\n",
    "from inception_resnet_v1 import *\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import add\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import numpy as np\n",
    "# PIL -> PythonImageLibrary\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전 학습된 모델 불러와서 기본 모델 생성하기\n",
    "# 'inceptionReNetV1()'의 경우 같은 경로에 저장된 inception_resnet_v1 파일 내부에 저장된 모델을 불러옴\n",
    "base_model = InceptionResNetV1(weights_path='./facenet_keras_weights.h5',\n",
    "                              input_shape=(224,224,3),\n",
    "                              dropout_keep_prob=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 모델 구조 확인하기\n",
    "\n",
    "print(base_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 모델의 각 계층 인덱스와 이름 확인하기\n",
    "# enumerate를 for문에 쓸 경우 인덱스와 담긴 값을 같이 가져옴\n",
    "for i , layer in enumerate(base_model.layers):\n",
    "    print(i, layer.name)\n",
    "    \n",
    "# 이렇게 모델의 계층 인덱스를 확인하는 이유는 전이학습을 위해 특성추출 부분과 \n",
    "# 분류 부분의 경계선을 구분하여전이학습 모델을 만들기 위함\n",
    "# Conv2d라는 부분을 통해 통해 연산하여 특성을 추출함(계층에 conv2d가 들어 있는건 모두 특성 추출)\n",
    "# Concatenate 이후 Block8_6_Conv2d_1x1로 펴주면 성능이 향상된다는 논문이 있어서 이렇게 펴줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainable = False를 이용하여 기본 모델의 전 계층 동결하기\n",
    "# 계층 동결시키는 이유? 학습을 시키지 않으면 모델의 성능을 개선하지 않고 그대로 사용함\n",
    "# 계층을 동결시키므로 대신 학습 시간을 줄일 수 있음\n",
    "# 즉 동결시키는 부분은 학습이 안되고 나머지 부분에서 학습을 시키는 거 자체가 전이학습임\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# 결과 확인\n",
    "print(base_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전이 학습 모델 정의 하기(분류 모델 부분만 전이학습 시킨 것)\n",
    "\n",
    "classes = 50\n",
    "\n",
    "x = base_model.get_layer(index=442).output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation = \"relu\",\n",
    "         kernel_initializer = \"he_normal\",\n",
    "         bias_initializer = \"zeros\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(classes, activation = \"softmax\")(x)\n",
    "\n",
    "my_model = Model(inputs = base_model.input, outputs=predictions)\n",
    "\n",
    "# 결과 확인\n",
    "print('base_model.get_layer(index=442).output의 모양 = ', base_model.get_layer(index=442).output.shape)\n",
    "print(\"전이 학습 모델의 입력인 base_model.input의 모양 = \", base_model.input.shape)\n",
    "print(\"전이 학습 모델의 출력인 predictions의 모양 = \", predictions.shape)\n",
    "\n",
    "print(my_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 증식시키지 않고 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습용 ImageDataGenerator() 함수에 증식에 관한 어떤 조건도 부여하지 않기\n",
    "\n",
    "# 1 뒤에 .를 찍는 이유는 정수 뒤에 .을 찍으면 정수가 실수로 바뀌므로 아래의 값이 정수가 아닌 실수로 바뀌므로\n",
    "train_datagen1 = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 검증용 ImageDataGenerator() 함수 설정\n",
    "val_datagen1 = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# 학습용 데이터와 검증용 데이터 경로 설정\n",
    "print(\"현재 경로 : \", os.getcwd())\n",
    "train_dir = os.getcwd() + \"/img/train\"\n",
    "val_dir = os.getcwd() + \"/img/val\"\n",
    "\n",
    "# flow_from_directory() 함수를 이용, ImgeDataGenerator()에 학습용 데이터, 테스트용 데이터 공급\n",
    "# target_size = (HEIGHT, WIDTH) : 이미지 크기 설정\n",
    "# keras 모델의 경우 높이를 먼저 써줘야함\n",
    "HEIGHT = 224\n",
    "WIDTH = 224\n",
    "\n",
    "# 폴더명 자체가 class가 됨 따라서(class는 goeun/gongyu이 됨)\n",
    "# flow_from_directory를 쓰면 저절로 폴더 이름을 label이라고 인식하도록 설계 되어 있음(부가기능)\n",
    "# flow_from_directory는 데이터를 연결시켜주는 기능을 함\n",
    "train_generator1 = train_datagen1.flow_from_directory(train_dir,\n",
    "                                                     batch_size=20,\n",
    "                                                     target_size=(HEIGHT,WIDTH),\n",
    "                                                     shuffle=True,\n",
    "                                                      # 클래스가 복수이고 다중 분류이므로 categorical를 활용함\n",
    "                                                      # 분류 모델의 경우 binary 모델을 활용\n",
    "                                                     class_mode=\"categorical\")\n",
    "\n",
    "val_generator1 = val_datagen1.flow_from_directory(val_dir,\n",
    "                            batch_size=20,\n",
    "                            target_size=(HEIGHT,WIDTH),\n",
    "                            shuffle=True,\n",
    "                            class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 결과를 저장할 디렉토리 생성\n",
    "checkpoint_dir = os.getcwd() + \"/model\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 과대 적합을 방지하기 위한 조기 종료 설정\n",
    "early_stop = EarlyStopping(monitor = 'val_loss', verbose = 1, patience= 5)\n",
    "\n",
    "# 최적의 학습 결과를 저장하기 위한 ModelCheckpoint 설정\n",
    "# min의 의미는 손실값이 최소화될 때마다 저장하게 만듦\n",
    "checkpoint = ModelCheckpoint(filepath=checkpoint_dir+\"/\"+\"no_augment_weight.h5\", monitor = \"val_loss\",\n",
    "                            verbose=1, mode='min', save_best_only=True)\n",
    "\n",
    "# 모델 컴파일\n",
    "loss = \"categorical_crossentropy\"\n",
    "optimizer = Adam(lr=0.0001)\n",
    "my_model.compile(loss = loss, optimizer = optimizer, metrics=[\"acc\"])\n",
    "\n",
    "# 학습 진행\n",
    "history = my_model.fit_generator(train_generator1,\n",
    "                                 steps_per_epoch=len(train_generator1),\n",
    "                                 epochs = 100,\n",
    "                                 validation_data = val_generator1,\n",
    "                                 validation_steps = len(val_generator1),\n",
    "                                 callbacks = [early_stop, checkpoint]\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 결과 시각화\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history[\"val_acc\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "epochs = range(1,len(acc)+1)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "# \"bo\"-> 파란색 점을 찍음 / \"b\"-> 파란색 선을 그려줌\n",
    "plt.plot(epochs, acc, \"bo\", label= \"Training acc\")\n",
    "plt.plot(epochs, val_acc, \"b\", label = \"Validation_acc\")\n",
    "plt.plot(epochs, loss, \"ro\", label = \"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"r\", label = \"Validation_loss\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습용 이미지를 증식시켜서 학습 시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageDataGenerator() 함수와 flow_from_directory() 함수를 사용\n",
    "\n",
    "# 학습용은 증식해야함\n",
    "train_datagen2 = ImageDataGenerator(rescale = 1./255,\n",
    "                                    rotation_range = 15,\n",
    "                                    width_shift_range = 0.15,\n",
    "                                    height_shift_range = 0.15,\n",
    "                                    # 찌그러 뜨리기(shear_range)\n",
    "                                    shear_range = 0.15,\n",
    "                                    zoom_range = 0.10,\n",
    "                                    horizontal_flip = True,\n",
    "                                    vertical_flip= True,\n",
    "                                    # 어떻게 채울지 선택하는 것(fill_mode)\n",
    "                                    fill_mode = \"nearest\"\n",
    "                                   )\n",
    "#검증용은 증식하면 안됌 검증에 쓰여야 하기 때문\n",
    "val_datagen2 = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# 데이터 경로 설정\n",
    "train_dir = os.getcwd()+\"/img/train\"\n",
    "val_dir = os.getcwd()+\"/img/val\"\n",
    "\n",
    "# flow_from_directory() 함수 이용, 데이터 공급\n",
    "train_generator2 = train_datagen2.flow_from_directory(train_dir,\n",
    "                                                     batch_size=30,\n",
    "                                                     target_size=(HEIGHT,WIDTH),\n",
    "                                                     shuffle=True,\n",
    "                                                     class_mode=\"categorical\"\n",
    "                                                     )\n",
    "\n",
    "val_generator2 = val_datagen2.flow_from_directory(val_dir,\n",
    "                                                  batch_size=10,\n",
    "                                                  target_size=(HEIGHT,WIDTH),\n",
    "                                                  shuffle=True,\n",
    "                                                  class_mode=\"categorical\"\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적의 학습 결과를 저장(대신 변수명을 다르게 지정해야함)\n",
    "checkpoint2 = ModelCheckpoint(filepath=checkpoint_dir+\"/\"+\"augment_weight.h5\", monitor = \"val_loss\",\n",
    "                            verbose=1, mode='min', save_best_only=True)\n",
    "\n",
    "history2 = my_model.fit_generator(train_generator2,\n",
    "                                  steps_per_epoch=len(train_generator2),\n",
    "                                  epochs = 100,\n",
    "                                  validation_data = val_generator2,\n",
    "                                  validation_steps = len(val_generator2),\n",
    "                                  callbacks = [early_stop, checkpoint2]                             \n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 결과 시각화\n",
    "acc = history2.history['acc']\n",
    "val_acc = history2.history[\"val_acc\"]\n",
    "loss = history2.history[\"loss\"]\n",
    "val_loss = history2.history[\"val_loss\"]\n",
    "\n",
    "epochs = range(1,len(acc)+1)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "# \"bo\"-> 파란색 점을 찍음 / \"b\"-> 파란색 선을 그려줌\n",
    "plt.plot(epochs, acc, \"bo\", label= \"Training acc\")\n",
    "plt.plot(epochs, val_acc, \"b\", label = \"Validation_acc\")\n",
    "plt.plot(epochs, loss, \"ro\", label = \"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"r\", label = \"Validation_loss\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습결과 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기\n",
    "\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 학습된 이미지 저장 경로 설정\n",
    "checkpoint_dir = os.getcwd() + '/model/'\n",
    "\n",
    "# 학습된 모델 불러오기\n",
    "model1 = load_model(checkpoint_dir + 'no_augment_weight.h5')\n",
    "\n",
    "# 결과 확인하기\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 폴더에 있는 이미지를 이용해서 인식 / 분류 실행\n",
    "\n",
    "# PIL -> PythonImageLibrary\n",
    "from PIL import Image\n",
    "\n",
    "# 이미지 사이즈 실행\n",
    "HEIGHT = 224\n",
    "WIDTH = 224\n",
    "\n",
    "# 테스트 이미지 경로 설정\n",
    "test_dir = os.getcwd() + \"/img/test/\"\n",
    "\n",
    "# 시각화를 위한 설정\n",
    "image_path = []\n",
    "\n",
    "\n",
    "# os.listdir() 해당 폴더 안에 있는 파일들을 리스트화 하여 보내줌\n",
    "for name in os.listdir(test_dir):\n",
    "    # 각 이미지의 절대 경로 설정\n",
    "    test_image_name = test_dir + name\n",
    "    print(test_image_name)\n",
    "    image_path.append(test_image_name)\n",
    "    \n",
    "# image_path : 테스트 이미지 각각의 절대 경로를 리스트로 저장\n",
    "print(\"\\n\")\n",
    "print(image_path)\n",
    "\n",
    "for image in image_path:\n",
    "    # Image.open() -> 이미지 불러오는 함수 <이 함수는 tuple로 전달하게 만들어짐>\n",
    "    img = Image.open(image)\n",
    "    print(\"\\n\")\n",
    "    print(\"img 자료형 확인 = {}\".format(type(img)))\n",
    "    img = img.resize((HEIGHT, WIDTH))\n",
    "    data = np.array(img)\n",
    "    print(\"data 자료형 확인 = {}\".format(type(data)))\n",
    "    X = np.array(data)\n",
    "    X = X.astype(\"float\")/255 # 타입을 정수에서 실수로 바꾸어 0~1의 정규화를 진행\n",
    "    X = X.reshape(-1, HEIGHT, WIDTH, 3)\n",
    "    categories = [\"baleut\",\"bulgogi\",\"burger\",\"chik\",\"cho\",\"coco\",\"dag\",\"dang\",\"don\",\n",
    "                \"dongbaek\",\"fish\",\"galbi\",\"go\",\"gwang\",\"han\",\"hang\",\"hong\",\n",
    "                \"hwang\",\"jamami\",\"jin\",\"jingal\",\"kagawa\",\"kao\",\"kor\",\"kum\",\"mali\",\n",
    "                \"mama\",\"man\",\"mok\",\"moon\",\"mul\",\"nak\",\"oct\",\"pong\",\"pyeon\",\"red\",\n",
    "                \"sakana\",\"sinbul\",\"sirae\",\"snake\",\"snoopy\",\"sot\",\"spa\",\"sukju\",\n",
    "                \"theflower\",\"two\",\"vivi\",\"yasmaru\",\"zerk\",\"zuk\"]\n",
    "    pred = model1.predict(X)\n",
    "\n",
    "    # [np.argmax()] 값의 최대값을 가져오는 함수\n",
    "    result = [np.argmax(value) for value in pred]\n",
    "    print('New image prediction : ',categories[result[0]])\n",
    "    print(\"accuracy : {}\".format(max(pred[0])))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 증식 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기\n",
    "\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 학습된 이미지 저장 경로 설정\n",
    "checkpoint_dir = os.getcwd() + '/model/'\n",
    "\n",
    "# 학습된 모델 불러오기\n",
    "model2 = load_model(checkpoint_dir + 'augment_weight.h5')\n",
    "\n",
    "# 결과 확인하기\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 폴더에 있는 이미지를 이용해서 인식 / 분류 실행\n",
    "\n",
    "# PIL -> PythonImageLibrary\n",
    "from PIL import Image\n",
    "\n",
    "# 이미지 사이즈 실행\n",
    "HEIGHT = 224\n",
    "WIDTH = 224\n",
    "\n",
    "# 테스트 이미지 경로 설정\n",
    "test_dir = os.getcwd() + \"/img/test/\"\n",
    "\n",
    "# 시각화를 위한 설정\n",
    "image_path = []\n",
    "\n",
    "\n",
    "# os.listdir() 해당 폴더 안에 있는 파일들을 리스트화 하여 보내줌\n",
    "for name in os.listdir(test_dir):\n",
    "    # 각 이미지의 절대 경로 설정\n",
    "    test_image_name = test_dir + name\n",
    "    print(test_image_name)\n",
    "    image_path.append(test_image_name)\n",
    "    \n",
    "# image_path : 테스트 이미지 각각의 절대 경로를 리스트로 저장\n",
    "print(\"\\n\")\n",
    "print(image_path)\n",
    "\n",
    "for image in image_path:\n",
    "    # Image.open() -> 이미지 불러오는 함수 <이 함수는 tuple로 전달하게 만들어짐>\n",
    "    img = Image.open(image)\n",
    "    print(\"\\n\")\n",
    "    print(\"img 자료형 확인 = {}\".format(type(img)))\n",
    "    img = img.resize((HEIGHT, WIDTH))\n",
    "    data = np.array(img)\n",
    "    print(\"data 자료형 확인 = {}\".format(type(data)))\n",
    "    X = np.array(data)\n",
    "    X = X.astype(\"float\")/255 # 타입을 정수에서 실수로 바꾸어 0~1의 정규화를 진행\n",
    "    X = X.reshape(1, HEIGHT, WIDTH, 3)\n",
    "    categories = [\"baleut\",\"bulgogi\",\"burger\",\"chik\",\"cho\",\"coco\",\"dag\",\"dang\",\"don\",\n",
    "                \"dongbaek\",\"fish\",\"galbi\",\"go\",\"gwang\",\"han\",\"hang\",\"hong\",\n",
    "                \"hwang\",\"jamami\",\"jin\",\"jingal\",\"kagawa\",\"kao\",\"kor\",\"kum\",\"mali\",\n",
    "                \"mama\",\"man\",\"mok\",\"moon\",\"mul\",\"nak\",\"oct\",\"pong\",\"pyeon\",\"red\",\n",
    "                \"sakana\",\"sinbul\",\"sirae\",\"snake\",\"snoopy\",\"sot\",\"spa\",\"sukju\",\n",
    "                \"theflower\",\"two\",\"vivi\",\"yasmaru\",\"zerk\",\"zuk\"]\n",
    "    pred = model2.predict(X)\n",
    "    # [np.argmax()] 값의 최대값을 가져오는 함수\n",
    "    result = [np.argmax(value) for value in pred]\n",
    "    print('New image prediction : ',categories[result[0]])\n",
    "#     print(\"accuracy : {}\".format(max(pred[0][0],pred[0][1])))\n",
    "    print(\"accuracy : {}\".format(max(pred[0])))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 안드로이드로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow import keras\n",
    "# export_path = \"./pb\"\n",
    "# model2.save(export_path, save_format='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pd 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# saved_model_dir = './pb'\n",
    "# converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "# converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "#                                        tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "# tflite_model = converter.convert()\n",
    "# open('./tf/converted_model.tflite', 'wb').write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 서버연동 위한 코드 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "# 다운받을 이미지 url\n",
    "url = \"https://firebasestorage.googleapis.com/v0/b/finfooproject.appspot.com/o/%EC%BD%94%EC%BD%94%EC%8A%A4%ED%86%A4%20(11).jpg?alt=media&token=f23be5a6-5aa4-42eb-b501-00134a9385ec\"\n",
    "\n",
    "# time check\n",
    "start = time.time()\n",
    "\n",
    "# 이미지 요청 및 다운로드\n",
    "urllib.request.urlretrieve(url, \"test.jpg\")\n",
    "\n",
    "# 이미지 다운로드 시간 체크\n",
    "print(time.time() - start)\n",
    "\n",
    "# 저장 된 이미지 확인\n",
    "img = Image.open(\"test.jpg\")\n",
    "img = img.resize((HEIGHT, WIDTH))\n",
    "data = np.array(img)\n",
    "print(\"data 자료형 확인 = {}\".format(type(data)))\n",
    "X = np.array(data)\n",
    "X = X.astype(\"float\")/255 # 타입을 정수에서 실수로 바꾸어 0~1의 정규화를 진행\n",
    "X = X.reshape(1, HEIGHT, WIDTH, 3)\n",
    "categories = [\"baleut\",\"bulgogi\",\"burger\",\"chik\",\"cho\",\"coco\",\"dag\",\"dang\",\"don\",\n",
    "                \"dongbaek\",\"fish\",\"galbi\",\"go\",\"gwang\",\"han\",\"hang\",\"hong\",\n",
    "                \"hwang\",\"jamami\",\"jin\",\"jingal\",\"kagawa\",\"kao\",\"kor\",\"kum\",\"mali\",\n",
    "                \"mama\",\"man\",\"mok\",\"moon\",\"mul\",\"nak\",\"oct\",\"pong\",\"pyeon\",\"red\",\n",
    "                \"sakana\",\"sinbul\",\"sirae\",\"snake\",\"snoopy\",\"sot\",\"spa\",\"sukju\",\n",
    "                \"theflower\",\"two\",\"vivi\",\"yasmaru\",\"zerk\",\"zuk\"]\n",
    "pred = model2.predict(X)\n",
    "# [np.argmax()] 값의 최대값을 가져오는 함수\n",
    "result = [np.argmax(value) for value in pred]\n",
    "print('New image prediction : ',categories[result[0]])\n",
    "#print(\"accuracy : {}\".format(max(pred[0][0],pred[0][1])))\n",
    "print(\"accuracy : {}\".format(max(pred[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
